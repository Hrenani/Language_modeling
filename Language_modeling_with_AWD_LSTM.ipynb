{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM4xBdBnHGfdz5fwoL9wzH4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hrenani/Language_modeling/blob/main/Language_modeling_with_AWD_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ztiiFng_XZ",
        "outputId": "548f6ee8-6b96-4250-aef8-466d3c2c06e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/890.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.6/890.6 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.15.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5L8ceyuhB64",
        "outputId": "1b0f2f71-d739-4735-ad02-f040601c9747"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.15.1\n",
            "  Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (2.32.3)\n",
            "Collecting torch==2.0.0 (from torchtext==0.15.1)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.15.1) (1.26.4)\n",
            "Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (919 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.30.5)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.15.1) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n",
            "Downloading torchtext-0.15.1-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.0.0 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1 triton-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"CUDA Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztvl_NYwhD11",
        "outputId": "ce18b7e2-6992-4a18-b46c-cb41d7ddb4fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "CUDA Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##import libraries"
      ],
      "metadata": {
        "id": "BJUVBzH3hG04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, IterableDataset, random_split\n",
        "\n",
        "import torch.optim as optim\n",
        "import torchmetrics as tm\n",
        "\n",
        "import tqdm\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "eMVsHnz0hINW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lib in [np, torch, torchtext, tqdm]:\n",
        "  print(lib.__name__, '-->', lib.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CUxYwm4hXDl",
        "outputId": "58338422-ae67-4653-fff8-4d877553dd00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy --> 1.26.4\n",
            "torch --> 2.0.0+cu117\n",
            "torchtext --> 0.15.1+cpu\n",
            "tqdm --> 4.66.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##utils"
      ],
      "metadata": {
        "id": "YBWX9og_hZi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "\n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val * n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "rFMSwUJshaG_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_trainable_params(model):\n",
        "  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n",
        "  return nums"
      ],
      "metadata": {
        "id": "9_QuPS9rhcVW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "co5HqFrIheNF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arguments"
      ],
      "metadata": {
        "id": "XiO2KbnPhhze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "\n",
        "batch_size = 80\n",
        "seq_len = 70\n",
        "\n",
        "embedding_dim = 300\n",
        "\n",
        "num_layers = 3\n",
        "hidden_dim = 1150\n",
        "dropoute = 0.1\n",
        "dropouti = 0.65\n",
        "dropouth = 0.3\n",
        "dropouto = 0.4\n",
        "weight_drop = 0\n",
        "\n",
        "lr = 30\n",
        "wd = 1.2e-6\n",
        "momentum = 0.9\n",
        "\n",
        "clip = 0.25\n",
        "\n",
        "wandb_enable = False"
      ],
      "metadata": {
        "id": "bhkc7ukDhiQb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker>=2.0.0"
      ],
      "metadata": {
        "id": "Yg2_6_j5hsSG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "q_glTv0hhuM1",
        "outputId": "b2b13b1f-143f-4abb-8355-5adbad37cf9c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d44344b7-d700-4909-a4f9-22b5dd268183\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d44344b7-d700-4909-a4f9-22b5dd268183\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving wikitext-2-v1.zip to wikitext-2-v1.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  /content/wikitext-2-v1.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HboaN3Ixhu-u",
        "outputId": "931633af-fa6a-4d8a-c96f-596a03f877c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/wikitext-2-v1.zip\n",
            "   creating: wikitext-2/\n",
            "  inflating: wikitext-2/wiki.test.tokens  \n",
            "  inflating: wikitext-2/wiki.valid.tokens  \n",
            "  inflating: wikitext-2/wiki.train.tokens  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/wikitext-2/wiki.train.tokens'\n",
        "valid_path = '/content/wikitext-2/wiki.valid.tokens'\n",
        "test_path = '/content/wikitext-2/wiki.test.tokens'\n",
        "\n",
        "def read_data_generator(file_path):\n",
        "  with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "      yield line\n",
        "\n",
        "train_iter = read_data_generator(train_path)\n",
        "valid_iter = read_data_generator(valid_path)\n",
        "test_iter = read_data_generator(test_path)"
      ],
      "metadata": {
        "id": "ENDNZ1AOhxWG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter_ = iter(train_iter)\n",
        "train_iter_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1h5PZBKh0sE",
        "outputId": "71cd55d9-48c9-4f09-a184-b344653f1187"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object read_data_generator at 0x7b096846d700>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(train_iter_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "JroJsSFPh3-9",
        "outputId": "bd023160-b9a3-4ec3-d47b-e7d271c52a6c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_sentence_length(data):\n",
        "  total_sentence_count = 0\n",
        "  total_sentence_length = 0\n",
        "\n",
        "  for line in data:\n",
        "    sentences = line.split('.')\n",
        "\n",
        "    for sentence in sentences:\n",
        "      tokens = sentence.strip().split()\n",
        "      sentence_length = len(tokens)\n",
        "\n",
        "      if sentence_length > 0:\n",
        "        total_sentence_count += 1\n",
        "        total_sentence_length += sentence_length\n",
        "  mean_sentence_length = total_sentence_length / (total_sentence_count)\n",
        "\n",
        "  print(f'Mean sentence length in Wikitext-2: {mean_sentence_length:.2f}')"
      ],
      "metadata": {
        "id": "ygGtxNzJh6MW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_sentence_length(train_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLcGW7sTh-T2",
        "outputId": "c13d0f65-2fdc-49f2-98bf-36a438ac638b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean sentence length in Wikitext-2: 21.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = [\"Hi Hosein I am very good :) nad yuo44 @tke \", \"you are yoiu!\",\":\"]\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "list(map(tokenizer,txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFej8TfZiC_l",
        "outputId": "cfe7b0b0-af3a-45bb-a80c-76f748f567b6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hi', 'hosein', 'i', 'am', 'very', 'good', ')', 'nad', 'yuo44', '@tke'],\n",
              " ['you', 'are', 'yoiu', '!'],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials = ['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "id": "KyNQJpj2iHIV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab(['hosein', 'hi', 'how'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAS356lJiJNV",
        "outputId": "5d4c8e21-4375-496f-ea02-f52fae3e3cf6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 9206, 416]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform teh data"
      ],
      "metadata": {
        "id": "nJRHufUiiMld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_process(raw_text_iter, seq_len):\n",
        "  data = torch.cat([torch.LongTensor(vocab(tokenizer(line))) for line in raw_text_iter])\n",
        "\n",
        "  M = len(data) // seq_len\n",
        "\n",
        "  r = len(data) % seq_len\n",
        "  data = torch.cat((data, torch.LongTensor([0]))) if r == 0 else data\n",
        "\n",
        "  inputs = data[:M*seq_len]\n",
        "  targets = data[1:M*seq_len+1]\n",
        "\n",
        "  inputs = inputs.reshape(-1, seq_len)\n",
        "  targets = targets.reshape(-1, seq_len)\n",
        "\n",
        "  return inputs, targets"
      ],
      "metadata": {
        "id": "QzwZ47BNiKCd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = data_process(train_iter, seq_len)\n",
        "x_valid, y_valid = data_process(valid_iter, seq_len)\n",
        "x_test, y_test = data_process(test_iter, seq_len)\n",
        "\n",
        "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knmV6yaAiPv9",
        "outputId": "c03144da-4849-4eb9-bd00-ab1db89bcafa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([29285, 70]),\n",
              " torch.Size([29285, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3063, 70]),\n",
              " torch.Size([3455, 70]),\n",
              " torch.Size([3455, 70]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom dataset"
      ],
      "metadata": {
        "id": "zOtbjltHiVTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModelDataset(Dataset):\n",
        "  def __init__(self, inputs, targets):\n",
        "    self.inputs = inputs\n",
        "    self.targets = targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.inputs.shape[0]\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.inputs[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "SJ3iZu_0iSSc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = LanguageModelDataset(x_train, y_train)\n",
        "valid_set = LanguageModelDataset(x_valid, y_valid)\n",
        "test_set = LanguageModelDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "AqDBp_kbiYUU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrNhX0PGiaf1",
        "outputId": "286cd285-48ec-4341-a485-a1c8768929e0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    9,  3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,\n",
              "          3869,    21,   780, 28780,     2,  6182,     3,  3849,     4,     1,\n",
              "          5023,    88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,\n",
              "           881,   629,   976,     2,    23,     8,  5790,   299,    12,   575,\n",
              "           232,    67,   452,    19, 13722,     5,   757,     3,  2500,    17,\n",
              "             1,  1767,  5637,     3,   155,     6,   246,   354,     6,   976,\n",
              "             2,    24,    23,     1,   237,    67,     6,     1,  3849,    93]),\n",
              " tensor([ 3849,  3869,   881,     9, 20000,    83,  3849,    88,     0,  3869,\n",
              "            21,   780, 28780,     2,  6182,     3,  3849,     4,     1,  5023,\n",
              "            88,    20,     2,  1837,  1018,     7,    14,  3849,  3869,   881,\n",
              "           629,   976,     2,    23,     8,  5790,   299,    12,   575,   232,\n",
              "            67,   452,    19, 13722,     5,   757,     3,  2500,    17,     1,\n",
              "          1767,  5637,     3,   155,     6,   246,   354,     6,   976,     2,\n",
              "            24,    23,     1,   237,    67,     6,     1,  3849,    93,     3]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "TWz6sudeieDV"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_batch, y_batch = next(iter(train_loader))\n",
        "x_batch.shape, y_batch.shape, x_batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMc5iwgBie_e",
        "outputId": "15a80009-298b-46ea-dd6d-942491389d7c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([80, 70]),\n",
              " torch.Size([80, 70]),\n",
              " tensor([[  347,     1,   567,  ...,   349,     2,    28],\n",
              "         [ 8788,    24,    57,  ...,    18,   454,     5],\n",
              "         [    3,   309,    55,  ...,     3,    45,  1169],\n",
              "         ...,\n",
              "         [   28,   135,     7,  ...,   303,     4, 13207],\n",
              "         [ 5406,   974,     3,  ...,     3,     1,  5406],\n",
              "         [   50,    51,   419,  ...,  2027,     6,  8589]]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "  print(inputs[0,0], targets[0,0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez77_gpjii1d",
        "outputId": "34431cb8-d35a-40a9-f1d5-87e47f79f7b5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(347) tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Model"
      ],
      "metadata": {
        "id": "eQMoQ26rimls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightDrop(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, module, weights, dropout=0.0):\n",
        "    super(WeightDrop, self).__init__()\n",
        "    self.module = module\n",
        "    self.weights = weights\n",
        "    self.dropout = dropout\n",
        "    self._setup()\n",
        "\n",
        "  def widget_demagnetizer_y2k_edition(*args, **kwargs):\n",
        "    return\n",
        "\n",
        "  def _setup(self):\n",
        "    if issubclass(type(self.module), torch.nn.RNNBase):\n",
        "      self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n",
        "\n",
        "      for name_w in self.weights:\n",
        "        print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n",
        "        w = getattr(self.module, name_w)\n",
        "        del self.module._parameters[name_w]\n",
        "        self.module.register_parameter(name_w + '_raw', nn.Parameter(w.data))\n",
        "\n",
        "  def _setweights(self):\n",
        "    for name_w in self.weights:\n",
        "      raw_w = getattr(self.module, name_w + '_raw')\n",
        "      w = None\n",
        "      # w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n",
        "      mask = torch.nn.functional.dropout(torch.ones_like(raw_w), p=self.dropout, training=True) * (1 - self.dropout)\n",
        "      setattr(self.module, name_w, raw_w * mask)\n",
        "\n",
        "  def forward(self, *args):\n",
        "    self._setweights()\n",
        "    return self.module.forward(*args)"
      ],
      "metadata": {
        "id": "f5twHgzmijjM"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embedded_dropout(embed, words, dropout=0.1, scale=None):\n",
        "  if dropout:\n",
        "    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(\n",
        "        embed.weight) / (1 - dropout)\n",
        "    masked_embed_weight = mask * embed.weight\n",
        "  else:\n",
        "    masked_embed_weight = embed.weight\n",
        "  if scale:\n",
        "    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n",
        "\n",
        "  padding_idx = embed.padding_idx\n",
        "  if padding_idx is None:\n",
        "    padding_idx = -1\n",
        "\n",
        "  embedding = torch.nn.functional.embedding(words, masked_embed_weight,\n",
        "                                            padding_idx, embed.max_norm, embed.norm_type,\n",
        "                                            embed.scale_grad_by_freq, embed.sparse)\n",
        "  return embedding"
      ],
      "metadata": {
        "id": "DQi0jcV4iwVw"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LockedDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LockedDropout, self).__init__()\n",
        "\n",
        "  def forward(self, x, dropout):\n",
        "    if not self.training or not dropout:\n",
        "      return x\n",
        "    m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n",
        "    mask = m.requires_grad_(False) / (1 - dropout)\n",
        "    mask = mask.expand_as(x)\n",
        "    return mask * x"
      ],
      "metadata": {
        "id": "_zWBhN5Piy7t"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AWD-LSTM Language Model"
      ],
      "metadata": {
        "id": "lGwAgrg7i3oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageModel(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n",
        "               dropoute=0.2, dropouti=0.2, dropouth=0.2, dropouto=0.2,\n",
        "               weight_drop=0.2):\n",
        "    super().__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.embedding.weight.data.uniform_(-0.1, 0.1)\n",
        "\n",
        "    self.lstms = []\n",
        "    self.lstms.append(nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    self.lstms.append(nn.LSTM(hidden_dim, embedding_dim, num_layers=1, dropout=0, batch_first=False))\n",
        "    if weight_drop > 0:\n",
        "      self.lstms = [WeightDrop(lstm, ['weight_hh_l0'], dropout=weight_drop) for lstm in self.lstms]\n",
        "    self.lstms = nn.ModuleList(self.lstms)\n",
        "\n",
        "    self.fc = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    self.fc.weight = self.embedding.weight\n",
        "\n",
        "    self.lockdrop = LockedDropout()\n",
        "    self.dropoute = dropoute\n",
        "    self.dropouti = dropouti\n",
        "    self.dropouth = dropouth\n",
        "    self.dropouto = dropouto\n",
        "    # print(dropoute, dropouti, dropouth, dropouto)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedding = embedded_dropout(self.embedding, src, dropout=self.dropoute if self.training else 0)\n",
        "    embedding = self.lockdrop(embedding, self.dropouti)\n",
        "\n",
        "    new_hiddens = []\n",
        "    for l, lstm in enumerate(self.lstms):\n",
        "      embedding, _ = lstm(embedding)\n",
        "      if l != self.num_layers-1:\n",
        "        embedding = self.lockdrop(embedding, self.dropouth)\n",
        "\n",
        "    embedding = self.lockdrop(embedding, self.dropouto)\n",
        "\n",
        "    prediction = self.fc(embedding)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "Dm0HpHeni4Dt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n",
        "                      hidden_dim=hidden_dim, num_layers=num_layers,\n",
        "                      dropoute=dropoute, dropouti=dropouti,\n",
        "                      dropouth=dropouth, dropouto=dropouto,\n",
        "                      weight_drop=weight_drop)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njsE-zCdjCUt",
        "outputId": "9f8bf9cf-29cb-4f88-84fe-7f25e6e9dd62"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (lstms): ModuleList(\n",
              "    (0): LSTM(300, 1150)\n",
              "    (1): LSTM(1150, 1150)\n",
              "    (2): LSTM(1150, 300)\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_trainable_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG8PI9BcjEvk",
        "outputId": "f9ea168a-9e8b-4782-aeab-dc6f95e6798f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.674182"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_trainable_params(model.embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLwejLeQjHE2",
        "outputId": "7978d524-4263-4bd1-8e20-102b0b902c3c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.6346"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_np = model.embedding.weight.cpu().detach().numpy()\n",
        "unique_rows, indices, counts = np.unique(data_np, axis = 0, return_index = True, return_counts = True)\n"
      ],
      "metadata": {
        "id": "4k2x4cV-jJUd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##perplexity"
      ],
      "metadata": {
        "id": "ELXp5QqMjN1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchmetrics as tm\n",
        "\n",
        "class Perplexity(tm.Metric):\n",
        "    def __init__(self):\n",
        "        super(Perplexity, self).__init__()\n",
        "        self.add_state(\"total_loss\", default=torch.tensor(0.0).to(device), dist_reduce_fx=\"sum\")\n",
        "        self.add_state(\"num_samples\", default=torch.tensor(0).to(device), dist_reduce_fx=\"sum\")\n",
        "        self.criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "    def update(self, logits, labels):\n",
        "        logits = logits.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        loss = self.criterion(logits.reshape(-1, logits.size(-1)), labels.reshape(-1))\n",
        "        self.total_loss += loss\n",
        "        self.num_samples += labels.numel()\n",
        "\n",
        "    def compute(self):\n",
        "        return torch.exp(self.total_loss / self.num_samples)\n",
        "\n",
        "    def reset(self):\n",
        "        self.total_loss = torch.tensor(0.0).to(device)\n",
        "        self.num_samples = torch.tensor(0).to(device)\n"
      ],
      "metadata": {
        "id": "c2N8tfqvjL2t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Config"
      ],
      "metadata": {
        "id": "iT7EHlc-jTz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "voqtYxvtjRh9",
        "outputId": "c6b67bdf-5ed4-4269-8329-0d2cffa145ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "metric = Perplexity().to(device)"
      ],
      "metadata": {
        "id": "kJ_OOo3Ujaf8"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "T23F3OqJjfbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch:\n",
        "        tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "      loss.backward()\n",
        "\n",
        "      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item(), n=len(targets))\n",
        "      metric.update(outputs, targets)\n",
        "\n",
        "      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n",
        "\n",
        "  return model, loss_train.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "A1Aax9T0jc4f"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "ua1PZCTmjnOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_loader, loss_fn, metric):\n",
        "  model.eval()\n",
        "  loss_eval = AverageMeter()\n",
        "  metric.reset()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs = inputs.t().to(device)\n",
        "      targets = targets.t().to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "      loss_eval.update(loss.item(), n=len(targets))\n",
        "\n",
        "      metric(outputs, targets)\n",
        "\n",
        "  return loss_eval.avg, metric.compute().item()"
      ],
      "metadata": {
        "id": "Rcv5Ag6Qji_A"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculate the loss for an untrained model using a few batches."
      ],
      "metadata": {
        "id": "zcSLfXl0jux8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim=300,\n",
        "                      hidden_dim=512, num_layers=2,\n",
        "                      dropoute=0.5).to(device)\n",
        "\n",
        "inputs, targets = next(iter(train_loader))\n",
        "inputs = inputs.to(device)\n",
        "targets = targets.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(inputs)\n",
        "  loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n",
        "\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTX8v7HTjsIt",
        "outputId": "0768fd22-11fd-49b1-c25a-faa7db955372"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "tensor(10.2747, device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.reshape(-1, outputs.shape[-1]).shape, targets.flatten().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfNKCtktjy9l",
        "outputId": "5a4574ee-4e56-4d69-ce4f-88db545e0ed5"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5600, 28782]), torch.Size([5600]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MzNZM5vRj1R8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Try to train and overfit the model on a small subset of the dataset."
      ],
      "metadata": {
        "id": "i2S9lpWij9id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LanguageModel(len(vocab), embedding_dim = embedding_dim,\n",
        "                      hidden_dim = hidden_dim, num_layers = num_layers,\n",
        "                      dropoute = dropoute).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.9, momentum = 0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAUVMEq_j4dl",
        "outputId": "05cb6810-bade-4195-a3f6-707a665064ec"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n",
            "Applying weight drop of 0.2 to weight_hh_l0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mini_train_size = 1000\n",
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ],
      "metadata": {
        "id": "OtTqR1s3kBH0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKuSjf1zkDVk",
        "outputId": "79a98a33-d984-48e2-c621-dbfa171548e5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [00:05<00:00,  8.80batch/s, loss=8.31, metric=4.06e+3]\n",
            "Epoch 1: 100%|██████████| 50/50 [00:05<00:00,  9.25batch/s, loss=7.19, metric=1.32e+3]\n",
            "Epoch 2: 100%|██████████| 50/50 [00:05<00:00,  9.26batch/s, loss=7.03, metric=1.13e+3]\n",
            "Epoch 3: 100%|██████████| 50/50 [00:05<00:00,  9.21batch/s, loss=6.97, metric=1.07e+3]\n",
            "Epoch 4: 100%|██████████| 50/50 [00:05<00:00,  9.21batch/s, loss=6.94, metric=1.03e+3]\n",
            "Epoch 5: 100%|██████████| 50/50 [00:05<00:00,  9.11batch/s, loss=6.88, metric=977]\n",
            "Epoch 6: 100%|██████████| 50/50 [00:05<00:00,  9.04batch/s, loss=6.8, metric=898]\n",
            "Epoch 7: 100%|██████████| 50/50 [00:05<00:00,  8.99batch/s, loss=6.73, metric=833]\n",
            "Epoch 8: 100%|██████████| 50/50 [00:05<00:00,  8.96batch/s, loss=6.65, metric=774]\n",
            "Epoch 9: 100%|██████████| 50/50 [00:05<00:00,  8.96batch/s, loss=6.57, metric=716]\n",
            "Epoch 10: 100%|██████████| 50/50 [00:05<00:00,  8.87batch/s, loss=6.5, metric=668]\n",
            "Epoch 11: 100%|██████████| 50/50 [00:05<00:00,  8.91batch/s, loss=6.45, metric=630]\n",
            "Epoch 12: 100%|██████████| 50/50 [00:05<00:00,  8.78batch/s, loss=6.37, metric=584]\n",
            "Epoch 13: 100%|██████████| 50/50 [00:05<00:00,  8.79batch/s, loss=6.3, metric=544]\n",
            "Epoch 14: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=6.27, metric=527]\n",
            "Epoch 15: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=6.2, metric=493]\n",
            "Epoch 16: 100%|██████████| 50/50 [00:05<00:00,  8.67batch/s, loss=6.17, metric=480]\n",
            "Epoch 17: 100%|██████████| 50/50 [00:05<00:00,  8.59batch/s, loss=6.12, metric=453]\n",
            "Epoch 18: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=6.07, metric=433]\n",
            "Epoch 19: 100%|██████████| 50/50 [00:05<00:00,  8.63batch/s, loss=6.02, metric=413]\n",
            "Epoch 20: 100%|██████████| 50/50 [00:05<00:00,  8.73batch/s, loss=5.95, metric=383]\n",
            "Epoch 21: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=5.9, metric=366]\n",
            "Epoch 22: 100%|██████████| 50/50 [00:05<00:00,  8.78batch/s, loss=5.9, metric=365]\n",
            "Epoch 23: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=5.83, metric=341]\n",
            "Epoch 24: 100%|██████████| 50/50 [00:05<00:00,  8.77batch/s, loss=5.78, metric=325]\n",
            "Epoch 25: 100%|██████████| 50/50 [00:05<00:00,  8.78batch/s, loss=5.77, metric=319]\n",
            "Epoch 26: 100%|██████████| 50/50 [00:05<00:00,  8.75batch/s, loss=5.71, metric=301]\n",
            "Epoch 27: 100%|██████████| 50/50 [00:05<00:00,  8.76batch/s, loss=5.67, metric=289]\n",
            "Epoch 28: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=5.63, metric=280]\n",
            "Epoch 29: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=5.61, metric=273]\n",
            "Epoch 30: 100%|██████████| 50/50 [00:05<00:00,  8.63batch/s, loss=5.54, metric=255]\n",
            "Epoch 31: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=5.5, metric=245]\n",
            "Epoch 32: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=5.5, metric=245]\n",
            "Epoch 33: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=5.44, metric=231]\n",
            "Epoch 34: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=5.4, metric=222]\n",
            "Epoch 35: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=5.35, metric=212]\n",
            "Epoch 36: 100%|██████████| 50/50 [00:05<00:00,  8.73batch/s, loss=5.34, metric=209]\n",
            "Epoch 37: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=5.29, metric=198]\n",
            "Epoch 38: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=5.26, metric=192]\n",
            "Epoch 39: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=5.2, metric=181]\n",
            "Epoch 40: 100%|██████████| 50/50 [00:05<00:00,  8.75batch/s, loss=5.2, metric=181]\n",
            "Epoch 41: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=5.15, metric=173]\n",
            "Epoch 42: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=5.12, metric=168]\n",
            "Epoch 43: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=5.1, metric=164]\n",
            "Epoch 44: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=5.07, metric=159]\n",
            "Epoch 45: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=5.01, metric=150]\n",
            "Epoch 46: 100%|██████████| 50/50 [00:05<00:00,  8.67batch/s, loss=4.99, metric=148]\n",
            "Epoch 47: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=4.97, metric=145]\n",
            "Epoch 48: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=4.9, metric=134]\n",
            "Epoch 49: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=4.89, metric=133]\n",
            "Epoch 50: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=4.89, metric=133]\n",
            "Epoch 51: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=4.83, metric=125]\n",
            "Epoch 52: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=4.8, metric=122]\n",
            "Epoch 53: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=4.77, metric=118]\n",
            "Epoch 54: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=4.71, metric=111]\n",
            "Epoch 55: 100%|██████████| 50/50 [00:05<00:00,  8.63batch/s, loss=4.73, metric=113]\n",
            "Epoch 56: 100%|██████████| 50/50 [00:05<00:00,  8.74batch/s, loss=4.71, metric=111]\n",
            "Epoch 57: 100%|██████████| 50/50 [00:05<00:00,  8.66batch/s, loss=4.67, metric=106]\n",
            "Epoch 58: 100%|██████████| 50/50 [00:05<00:00,  8.73batch/s, loss=4.61, metric=100]\n",
            "Epoch 59: 100%|██████████| 50/50 [00:05<00:00,  8.65batch/s, loss=4.6, metric=99.7]\n",
            "Epoch 60: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=4.54, metric=93.2]\n",
            "Epoch 61: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=4.54, metric=93.8]\n",
            "Epoch 62: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=4.51, metric=91]\n",
            "Epoch 63: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=4.46, metric=86.7]\n",
            "Epoch 64: 100%|██████████| 50/50 [00:05<00:00,  8.65batch/s, loss=4.44, metric=84.5]\n",
            "Epoch 65: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=4.43, metric=83.8]\n",
            "Epoch 66: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=4.38, metric=80]\n",
            "Epoch 67: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=4.34, metric=77.1]\n",
            "Epoch 68: 100%|██████████| 50/50 [00:05<00:00,  8.66batch/s, loss=4.29, metric=73]\n",
            "Epoch 69: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=4.32, metric=75.4]\n",
            "Epoch 70: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=4.29, metric=73.1]\n",
            "Epoch 71: 100%|██████████| 50/50 [00:05<00:00,  8.66batch/s, loss=4.25, metric=69.8]\n",
            "Epoch 72: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=4.19, metric=65.8]\n",
            "Epoch 73: 100%|██████████| 50/50 [00:05<00:00,  8.67batch/s, loss=4.19, metric=65.9]\n",
            "Epoch 74: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=4.14, metric=62.9]\n",
            "Epoch 75: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=4.13, metric=62.4]\n",
            "Epoch 76: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=4.09, metric=59.8]\n",
            "Epoch 77: 100%|██████████| 50/50 [00:05<00:00,  8.66batch/s, loss=4.1, metric=60.4]\n",
            "Epoch 78: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=4.04, metric=56.8]\n",
            "Epoch 79: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=3.98, metric=53.7]\n",
            "Epoch 80: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=3.95, metric=52.1]\n",
            "Epoch 81: 100%|██████████| 50/50 [00:05<00:00,  8.67batch/s, loss=3.92, metric=50.2]\n",
            "Epoch 82: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=3.89, metric=49.1]\n",
            "Epoch 83: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=3.86, metric=47.4]\n",
            "Epoch 84: 100%|██████████| 50/50 [00:05<00:00,  8.62batch/s, loss=3.8, metric=44.8]\n",
            "Epoch 85: 100%|██████████| 50/50 [00:05<00:00,  8.73batch/s, loss=3.83, metric=46.1]\n",
            "Epoch 86: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=3.76, metric=43.1]\n",
            "Epoch 87: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=3.73, metric=41.5]\n",
            "Epoch 88: 100%|██████████| 50/50 [00:05<00:00,  8.65batch/s, loss=3.69, metric=40.1]\n",
            "Epoch 89: 100%|██████████| 50/50 [00:05<00:00,  8.71batch/s, loss=3.66, metric=38.8]\n",
            "Epoch 90: 100%|██████████| 50/50 [00:05<00:00,  8.69batch/s, loss=3.63, metric=37.7]\n",
            "Epoch 91: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=3.58, metric=36]\n",
            "Epoch 92: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=3.59, metric=36.4]\n",
            "Epoch 93: 100%|██████████| 50/50 [00:05<00:00,  8.67batch/s, loss=3.57, metric=35.6]\n",
            "Epoch 94: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=3.55, metric=34.7]\n",
            "Epoch 95: 100%|██████████| 50/50 [00:05<00:00,  8.68batch/s, loss=3.47, metric=32]\n",
            "Epoch 96: 100%|██████████| 50/50 [00:05<00:00,  8.72batch/s, loss=3.48, metric=32.4]\n",
            "Epoch 97: 100%|██████████| 50/50 [00:05<00:00,  8.65batch/s, loss=3.49, metric=32.8]\n",
            "Epoch 98: 100%|██████████| 50/50 [00:05<00:00,  8.75batch/s, loss=3.42, metric=30.5]\n",
            "Epoch 99: 100%|██████████| 50/50 [00:05<00:00,  8.70batch/s, loss=3.35, metric=28.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model for a limited number of epochs, experimenting with various learning rates."
      ],
      "metadata": {
        "id": "9lYEugFEkJSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1\n",
        "for lr in [30, 20, 15, 10, 7.5, 5, 2.5, 2, 1, 0.9, 0.5, 0.3, 0.1, 0.001, 0.0001]:\n",
        "  print(f'LR= {lr}')\n",
        "\n",
        "  modle = LanguageModel(vocab_size= len(vocab), embedding_dim = embedding_dim,\n",
        "                        hidden_dim = hidden_dim, num_layers = num_layers,\n",
        "                        dropoute = dropoute, dropouti = dropouti,\n",
        "                        dropouth = dropouth, dropouto = dropouto,\n",
        "                        weight_drop = weight_drop).to(device)\n",
        "\n",
        "  optimmizer = optim.SGD(model.parameters(), lr = lr, weight_decay = wd, momentum = momentum)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LeLs-icFkGVZ",
        "outputId": "e9edfc47-6ce6-4d5d-e9b2-29dca257f68f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR= 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:14<00:00,  2.73batch/s, loss=6.18, metric=482]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:14<00:00,  2.74batch/s, loss=5.9, metric=365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.77, metric=319]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.66, metric=288]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 7.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.57, metric=262]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:14<00:00,  2.74batch/s, loss=5.49, metric=243]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 2.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.42, metric=225]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.35, metric=211]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.75batch/s, loss=5.3, metric=199]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.25, metric=190]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.19, metric=180]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:14<00:00,  2.74batch/s, loss=5.14, metric=171]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:13<00:00,  2.74batch/s, loss=5.1, metric=164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 367/367 [02:14<00:00,  2.74batch/s, loss=5.06, metric=158]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LR= 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 63/367 [00:23<01:52,  2.69batch/s, loss=5.04, metric=155]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-6cb71036e911>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-e35953940481>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 2.5\n",
        "wd = 1e-6\n",
        "optimizer = optim.SGD(model.parameters(), lr = lr, weight_decay = wd, momentum = 0.9)\n"
      ],
      "metadata": {
        "id": "leRmRUU8kNL0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "metric_train_hist = []\n",
        "metric_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "7TCCPOemkild"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(1, num_epochs+1):\n",
        "  #train\n",
        "  model, loss_train, metric_train = train_one_epoch(model,\n",
        "                                                    train_loader,\n",
        "                                                    loss_fn,\n",
        "                                                    optimizer,\n",
        "                                                    metric,\n",
        "                                                    epoch)\n",
        "  #validation\n",
        "  loss_valid, metric_valid = evaluate(model,\n",
        "                                     valid_loader,\n",
        "                                     loss_fn,\n",
        "                                     metric)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'language_model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "    print('Model Saved!')\n",
        "\n",
        "  print(f'Valid: loss = {loss_valid: .4}, Metric = {metric_valid: .4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "SdF23qdskk1E",
        "outputId": "dd7809bf-6d06-4517-f55a-9ecf2da7d456"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.09, metric=59.5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.654, Metric =  105.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.07, metric=58.8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.657, Metric =  105.8\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.06, metric=57.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.655, Metric =  105.6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.04, metric=57]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.651, Metric =  105.2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.04, metric=56.6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.657, Metric =  105.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.02, metric=56]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.649, Metric =  104.9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4.01, metric=55.2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.646, Metric =  104.7\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 367/367 [02:15<00:00,  2.71batch/s, loss=4, metric=54.7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.649, Metric =  105.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 367/367 [02:15<00:00,  2.70batch/s, loss=3.99, metric=53.9]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid: loss =  4.662, Metric =  106.3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10:   4%|▎         | 13/367 [00:05<02:20,  2.53batch/s, loss=3.91, metric=50]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-786dbbcc8081>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-e35953940481>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"best_metric_valid is {metric_valid: .4}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLs7f3RQQRLK",
        "outputId": "a689e20b-9687-41c7-d156-b21ca0f6e23f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_metric_valid is  103.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot"
      ],
      "metadata": {
        "id": "oDVQqp2PktCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "\n",
        "plt.plot(range(epoch_counter), loss_train_hist, 'r-', label = \"Train\")\n",
        "plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label = \"Validation\")\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "b7qlgPB8krz2",
        "outputId": "ad9b893e-3e35-40e9-c356-042715070770"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b095540f760>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Test**"
      ],
      "metadata": {
        "id": "-toN-PeJk0nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'language_model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwAZDMPOkx1V",
        "outputId": "a7b9c8a0-d6e4-4b07-f22a-dd69d63d780b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (lstms): ModuleList(\n",
              "    (0): WeightDrop(\n",
              "      (module): LSTM(300, 1150)\n",
              "    )\n",
              "    (1): WeightDrop(\n",
              "      (module): LSTM(1150, 1150)\n",
              "    )\n",
              "    (2): WeightDrop(\n",
              "      (module): LSTM(1150, 300)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n",
        "metric_valid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw2h3FKTk4HM",
        "outputId": "0e16ef06-5acd-4d06-f482-d99a1c5b4eaf"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103.43798828125"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate**"
      ],
      "metadata": {
        "id": "auQ1Fy1Hk8xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'language_model.pt'\n",
        "model = torch.load(model_path)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr6mOl89k6Dr",
        "outputId": "84a9693c-6166-485c-a076-260196d9308f"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageModel(\n",
              "  (embedding): Embedding(28782, 300)\n",
              "  (lstms): ModuleList(\n",
              "    (0): WeightDrop(\n",
              "      (module): LSTM(300, 1150)\n",
              "    )\n",
              "    (1): WeightDrop(\n",
              "      (module): LSTM(1150, 1150)\n",
              "    )\n",
              "    (2): WeightDrop(\n",
              "      (module): LSTM(1150, 300)\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=300, out_features=28782, bias=True)\n",
              "  (lockdrop): LockedDropout()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, max_seq_len, temperature, mode, tokenizer, vocab, seed=None):\n",
        "  if seed is not None:\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "  indices = vocab(tokenizer(prompt))\n",
        "  itos = vocab.get_itos()\n",
        "\n",
        "  for i in range(max_seq_len):\n",
        "    src = torch.LongTensor(indices).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      prediction = model(src)\n",
        "\n",
        "    probs = torch.softmax(prediction[-1]/ temperature, dim = 0)\n",
        "\n",
        "    idx = vocab['<ukn>']\n",
        "    while idx == vocab['<ukn']:\n",
        "      idx = torch.multinomial(probs, num_samples = 1).item()\n",
        "\n",
        "    token = itos[idx]\n",
        "    prompt += ' ' + token\n",
        "\n",
        "    if idx == vocab['.']:\n",
        "      return prompt\n",
        "\n",
        "    indices.append(idx)\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "PqkGUWPOlAIM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = 'In a galaxy far, far away, there'\n",
        "prompt_2 = 'The sun was setting in the'\n",
        "prompt_3 = 'Once upon a time, there lived a young princess named'\n",
        "prompt_4 = 'What is the meaning '\n",
        "\n",
        "generate(prompt_1, 35, 0.5, model, tokenizer, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "qc5PYtt7lGpd",
        "outputId": "0f5e60a8-0707-45d0-c452-514d51863ef0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In a galaxy far, far away, there is a lot of people who have to do a lot of people .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt_2, 35, 0.5, model, tokenizer, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "nQvIyDG_O829",
        "outputId": "393847af-8539-41c5-b1e0-80a99de6bf56"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The sun was setting in the second volume of the poem .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt_3, 35, 0.5, model, tokenizer, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "RP7EDK5bO_24",
        "outputId": "14d84b47-6dc3-424b-de18-1f11fd83da68"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Once upon a time, there lived a young princess named , and was a child , from the art of the first time , and in the same year , he was a member of the company ' s department of education , a upper\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt_4, 35, 0.5, model, tokenizer, vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "FGDPSlpLPBRx",
        "outputId": "f34414c8-f17f-4c1d-a294-bb7212d56b66"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What is the meaning  of the man of the dead .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}